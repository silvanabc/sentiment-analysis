# Study of Multimodal Sentiment Analysis

Project: Multimodal Sentiment Analysis for TV Program Video

Supervisors:  Ismail HARRANDO, Alison REBOUD and Raphael TRONCY

## Description

The goal of this project is to perform a multimodal sentiment analysis in videos using audio, textual and visual features.


You can find a more detailed explanation about the study in [this report](You%20can%20find%20more%20detailed%20explanation%20about%20the%20study%20in%20this%20link%20%28https://drive.google.com/file/d/1YQoqTLmis9t9ulp3FnSNP0jm5MnkdrPw/view?usp=sharing%29).

Based on the articles “[Context-Dependent Sentiment Analysis in User-Generated Videos](https://www.researchgate.net/publication/318739364_Context-Dependent_Sentiment_Analysis_in_User-Generated_Videos)” and "[Multi-level Multiple Attentions for Contextual Multimodal Sentiment Analysis](https://www.researchgate.net/publication/321892427_Multi-level_Multiple_Attentions_for_Contextual_Multimodal_Sentiment_Analysis)".

The [MOSI Dataset](https://www.researchgate.net/publication/304164029_MOSI_Multimodal_Corpus_of_Sentiment_Intensity_and_Subjectivity_Analysis_in_Online_Opinion_Videos) was used to test the models presented on the papers. 


## Content Description

### notebooks
Jupyter Notebooks that were used to process the video features.

### features 
Python scripts to process video features among several videos.

### outputs
outputs from the codes
