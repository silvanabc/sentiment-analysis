{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOSI Text Extraction\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import gensim.models as g\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Todo: import from utils\n",
    "def pad_array(array, size):\n",
    "    array_qtt = array.shape[0]\n",
    "\n",
    "    if(array_qtt == size):\n",
    "        return array\n",
    "\n",
    "    if(array_qtt < size): #pad with 0\n",
    "\n",
    "        pad_left_count = int((size - array_qtt) / 2)\n",
    "        pad_right_count = size - array_qtt - pad_left_count\n",
    "\n",
    "        pad_left = np.zeros((pad_left_count,) + array.shape[1:])\n",
    "        pad_right = np.zeros((pad_right_count,) + array.shape[1:])\n",
    "\n",
    "        result_array = np.concatenate((array, pad_left , pad_right))\n",
    "\n",
    "    else: #resize\n",
    "        print('Resize')\n",
    "        result_array = np.resize(array.mean(axis=0).astype(int),\n",
    "                                 (size,) + array.shape[1:])\n",
    "    return result_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/silvana/Library/Mobile Documents/com~apple~CloudDocs/EURECOM/SemProj/Raw - MOSI Dataset/Transcript/Segmented/'\n",
    "standard_train_fold=['2iD-tVS8NPw', '8d-gEyoeBzc', 'Qr1Ca94K55A', 'Ci-AH39fi3Y', '8qrpnFRGt2A', 'Bfr499ggo-0', 'QN9ZIUWUXsY', '9T9Hf74oK10', '7JsX8y1ysxY', '1iG0909rllw', 'Oz06ZWiO20M', 'BioHAh1qJAQ', '9c67fiY0wGQ', 'Iu2PFX3z_1s', 'Nzq88NnDkEk', 'Clx4VXItLTE', '9J25DZhivz8', 'Af8D0E4ZXaw', 'TvyZBvOMOTc', 'W8NXH0Djyww', '8OtFthrtaJM', '0h-zjBukYpk', 'Vj1wYRQjB-o', 'GWuJjcEuzt8', 'BI97DNYfe5I', 'PZ-lDQFboO8', '1DmNV9C1hbY', 'OQvJTdtJ2H4', 'I5y0__X72p0', '9qR7uwkblbs', 'G6GlGvlkxAQ', '6_0THN4chvY', 'Njd1F0vZSm4', 'BvYR0L6f2Ig', '03bSnISJMiM', 'Dg_0XKD0Mf4', '5W7Z1C_fDaE', 'VbQk4H8hgr0', 'G-xst2euQUc', 'MLal-t_vJPM', 'BXuRRbG0Ugk', 'LSi-o-IrDMs', 'Jkswaaud0hk', '2WGyTLYerpo', '6Egk_28TtTM', 'Sqr0AcuoNnk', 'POKffnXeBds', '73jzhE8R1TQ', 'OtBXNcAL_lE', 'HEsqda8_d0Q', 'VCslbP0mgZI', 'IumbAb8q2dM']\n",
    "standard_valid_fold=['WKA5OygbEKI', 'c5xsKMxpXnc', 'atnd_PF-Lbs', 'bvLlb-M3UXU', 'bOL9jKpeJRs', '_dI--eQ6qVU', 'ZAIRrfG22O0', 'X3j2zQgwYgE', 'aiEXnCPZubE', 'ZUXBRvtny7o']\n",
    "standard_test_fold=['tmZoasNr4rU', 'zhpQhgha_KU', 'lXPQBPVc5Cw', 'iiK8YX8oH1E', 'tStelxIAHjw', 'nzpVDcQ0ywM', 'etzxEpPuc6I', 'cW1FSBF59ik', 'd6hH302o4v8', 'k5Y_838nuGo', 'pLTX3ipuDJI', 'jUzDDGyPkXU', 'f_pcplsH_V0', 'yvsjCA6Y5Fc', 'nbWiPyCm4g0', 'rnaNMUZpvvg', 'wMbj6ajWbic', 'cM3Yna7AavY', 'yDtzw_Y-7RU', 'vyB00TXsimI', 'dq3Nf_lMPnE', 'phBUpBr1hSo', 'd3_k5Xpfmik', 'v0zCBqDeKcE', 'tIrG4oNLFzE', 'fvVhgmXxadc', 'ob23OKe5a9Q', 'cXypl4FnoZo', 'vvZ4IcEtiZc', 'f9O3YtZ2VfI', 'c7UH_rxdZv4']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "m = g.Doc2Vec.load('../apnews_dbow/doc2vec.bin')\n",
    "\n",
    "#model_parameters\n",
    "max_utterance = 63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '../OpinionLevelSentiment.csv'\n",
    "labelsDF = pd.read_csv(csv_path, skiprows=0, names=['start', 'end', 'video_id', 'segment', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_vec(filenames, labelsDF):\n",
    "    result = []\n",
    "    count = 1\n",
    "    \n",
    "    length = []\n",
    "    labels = []\n",
    "    \n",
    "    for filename in sorted(filenames):\n",
    "        with open(path + filename + '.annotprocessed', 'r') as file:\n",
    "            txt = file.read()\n",
    "        utterances = txt.strip().split('\\n')\n",
    "        utterances = [u[u.find('_DELIM_') + 7:].strip() for u in utterances]\\\n",
    "        \n",
    "        #utterance quantity in each video\n",
    "        length.append(len(utterances))\n",
    "\n",
    "        utdocvec = []\n",
    "        for i, u in enumerate(utterances):\n",
    "            utdocvec.append([str(x) for x in m.infer_vector(u.split(\" \"))])\n",
    "            \n",
    "        \n",
    "        #get labels\n",
    "        df_segment = labelsDF[labelsDF.video_id == filename].sort_values(by=['segment'])\n",
    "        scores = df_segment['score'].values\n",
    "        labels.append(pad_array(scores, max_utterance))\n",
    "            \n",
    "        result.append(pad_array(np.array(utdocvec), max_utterance))\n",
    "        \n",
    "        \n",
    "    return np.array(result), length, np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, test_length, test_label = get_doc_vec(standard_test_fold, labelsDF)\n",
    "# np.save('mosi_text_test', test)\n",
    "\n",
    "train, train_length, train_label = get_doc_vec(standard_train_fold + standard_valid_fold, labelsDF)\n",
    "# np.save('mosi_text_train', train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "pickle_path = \"../mosi_text_pad_right_sorted.pkl\"\n",
    "\n",
    "data = train, train_label, test, test_label, train.shape[1], train_length, test_length\n",
    "\n",
    "pickle_out = open(pickle_path, \"wb\")\n",
    "pickle.dump(data, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
